{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from wit import Wit\n",
    "import pandas as pd\n",
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.Selected_comments_with_witai_sentiment_results\n",
    "## import comment with side effects for query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "SE_tem_l400 = pd.read_csv(\"wit_ai_sentment/SE_tem_l400.csv\",index_col=0,header=None)[1]\n",
    "SE_tem_l400 = SE_tem_l400.iloc[3:].astype(str)\n",
    "idxs = list(SE_tem_l400.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## query against wit.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-22:\n",
      "Process ForkPoolWorker-23:\n",
      "Process ForkPoolWorker-21:\n",
      "Process ForkPoolWorker-19:\n",
      "Process ForkPoolWorker-20:\n",
      "Process ForkPoolWorker-24:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/jzz0026/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "access_token='TPGKFHFWL6UWQ2MNBTX7LBVKZP4FNYWN'\n",
    "client = Wit(access_token)\n",
    "\n",
    "sentments = {}\n",
    "\n",
    "test = SE_tem_l400#.iloc[:10]\n",
    "\n",
    "def sent_one_message(idx):\n",
    "    b = SE_tem_l400.loc[idx]\n",
    "    try:\n",
    "        res = client.message(b)#['entities']\n",
    "        return [idx,res]\n",
    "    \n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "\n",
    "pool_size = 6\n",
    "pool = multiprocessing.Pool(pool_size)\n",
    "test = pool.map(sent_one_message, idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2= [a for a in test if a != None]\n",
    "first_quest = pd.DataFrame(test2).set_index(0)\n",
    "#first_quest.to_csv(\"SE_tem_l400_first_request.scv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jzz0026/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/jzz0026/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/jzz0026/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>confidence</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>206461</th>\n",
       "      <td>It has no side effect, I take it in combinatio...</td>\n",
       "      <td>0.859484</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92703</th>\n",
       "      <td>I used to take another oral contraceptive, whi...</td>\n",
       "      <td>0.669752</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102654</th>\n",
       "      <td>Only side effect is I like to eat a lot</td>\n",
       "      <td>0.544129</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75612</th>\n",
       "      <td>Best thing, no side effects</td>\n",
       "      <td>0.801017</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81890</th>\n",
       "      <td>It has since subsided and the only side effect...</td>\n",
       "      <td>0.501730</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  confidence  \\\n",
       "0                                                                       \n",
       "206461  It has no side effect, I take it in combinatio...    0.859484   \n",
       "92703   I used to take another oral contraceptive, whi...    0.669752   \n",
       "102654            Only side effect is I like to eat a lot    0.544129   \n",
       "75612                         Best thing, no side effects    0.801017   \n",
       "81890   It has since subsided and the only side effect...    0.501730   \n",
       "\n",
       "           value  \n",
       "0                 \n",
       "206461   neutral  \n",
       "92703   positive  \n",
       "102654   neutral  \n",
       "75612   positive  \n",
       "81890    neutral  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_quest[2] = first_quest[1].apply(lambda x : x['entities'])\n",
    "first_quest2 = first_quest[first_quest[2] != {}]\n",
    "first_quest2[\"confidence\"] = first_quest2[2].apply(lambda x : x['sentiment'][0]['confidence'])\n",
    "first_quest2['value'] = first_quest2[2].apply(lambda x : x['sentiment'][0]['value'])\n",
    "first_quest2['text'] = first_quest2[1].apply(lambda x: x['_text'])# = \n",
    "\n",
    "first_quest2 = first_quest2[['text','confidence','value']]\n",
    "first_quest2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#first_quest2.to_csv(\"wit_ai_sentment/SE_tem_l400_first_request.ccv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total results: 30689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "value\n",
       "negative    16765\n",
       "neutral     12010\n",
       "positive     1914\n",
       "dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Total results:\",len(first_quest2))\n",
    "first_quest2.groupby('value').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Don't be scared by the minor side effects, because they are not greater then a baby\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_quest2[first_quest2['value'] == 'negative'].sample(1)['text'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Train the model using only these comment with side effects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "import re\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## only need to remove punctuation and stemize\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## remove special symbol\n",
    "def rm_sym(df):\n",
    "    df['review'] = df['review'].str.replace(\"&#039;\",'\\'')\n",
    "    df['review'].head()\n",
    "    df['rating_cate'] = ''\n",
    "    df.loc[df['rating'] >= 7,'rating_cate'] = 'high'\n",
    "    df.loc[df['rating'] <= 4,'rating_cate'] = 'low'\n",
    "    df.loc[(df['rating'] > 4) & (df['rating'] < 7),'rating_cate'] = 'medium'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('drugsCom_raw/drugsComTrain_raw.tsv',sep='\\t',index_col=0)\n",
    "df = rm_sym(df)\n",
    "\n",
    "\n",
    "test = pd.read_csv(\"drugsCom_raw/drugsComTest_raw.tsv\",sep='\\t', index_col=0)\n",
    "test = rm_sym(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jzz0026/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([df.loc[first_quest2.index], first_quest2],1)\n",
    "## Generate table of words with their counts\n",
    "con_vec = TfidfVectorizer(stop_words='english',tokenizer=tokenize)\n",
    "X_train_p = con_vec.fit_transform(train['review'])\n",
    "y_train = train['rating_cate']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30689,)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "negnornot = (train['value'] == \"negative\").astype(int)\n",
    "negnornot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<30689x24463 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1167174 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import hstack\n",
    "\n",
    "X_train_dtm = hstack((X_train_p,np.array(negnornot)[:,None]))\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7862379 , 0.79061584, 0.78607743])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression(penalty='l1',multi_class='auto',solver='saga')\n",
    "#lr.fit(X,target_3.iloc[:,0])\n",
    "\n",
    "cv_score = cross_val_score(lr,X_train_dtm,y_train,scoring='accuracy',cv=3,n_jobs=-1)\n",
    "cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83647737, 0.84154448, 0.83525616])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(n_estimators=300,n_jobs=-1)\n",
    "rfc_cv_score = cross_val_score(rfc,X_train_dtm,y_train,scoring='accuracy',cv=3,n_jobs=-1)\n",
    "rfc_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## n_estimators=300\n",
    "## array([0.83647737, 0.84154448, 0.83525616])\n",
    "\n",
    "## n_estimators=200\n",
    "## array([0.83686834, 0.84183773, 0.83633164])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient boosting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.7762682 , 0.77800587, 0.77620258])"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gbc = GradientBoostingClassifier(n_estimators=300)\n",
    "gbc_cv_score = cross_val_score(gbc,X_train_dtm,y_train,scoring='accuracy',cv=3,n_jobs=-1)\n",
    "gbc_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### poly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.71342   , 0.71348974, 0.71353148])"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_poly = SVC(kernel='poly')\n",
    "gbc_cv_score = cross_val_score(svm_poly,X_train_dtm,y_train,scoring='accuracy',cv=3,n_jobs=-1)\n",
    "gbc_cv_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.79962858, 0.80371457, 0.80201408])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_lin = SVC(kernel='linear')\n",
    "gbc_cv_score = cross_val_score(svm_lin,X_train_dtm,y_train,scoring='accuracy',cv=3,n_jobs=-1)\n",
    "gbc_cv_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
